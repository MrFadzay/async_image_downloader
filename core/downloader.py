"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
"""
import asyncio
import random
from pathlib import Path
from typing import List, Tuple
import time
import aiofiles.os
from curl_cffi import AsyncSession
from curl_cffi.requests import errors

from core.image_utils import process_and_save_image_sync
from utils.config import (
    DEFAULT_DOWNLOAD_DIR_NAME,
    DOWNLOAD_TIMEOUT,
    USER_AGENTS,
    IMAGE_DIR,
    MAX_CONCURRENT_DOWNLOADS,
)
from utils.logger import logger
from utils.validation import (
    validate_download_request,
    validate_file_size,
    validate_mime_type,
)
from utils.resource_manager import get_resource_manager
from utils.progress import get_progress_tracker, show_download_stats
from utils.session_manager import get_session_manager
from utils.error_handling import get_error_handler


async def create_dir(dir_name: Path) -> None:
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    await aiofiles.os.makedirs(dir_name, exist_ok=True)


# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –≤ —Ü–µ–ª–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
async def generate_unique_filename(
        target_dir: Path, base_filename: str) -> Path:
    new_filename = f"{base_filename}.jpeg"
    full_path = target_dir / new_filename
    counter = 1
    while await aiofiles.os.path.exists(full_path):
        new_filename = f"{base_filename}.{counter}.jpeg"
        full_path = target_dir / new_filename
        counter += 1
    return full_path

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è


async def handle_and_save_response(
    image_data: bytes,
    headers: dict,
    full_path: Path,
    url: str,
    min_size: int = 100,
) -> bool:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–≤–µ—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫.
    
    Args:
        image_data: –î–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        headers: HTTP –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞
        full_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
        url: –ò—Å—Ö–æ–¥–Ω—ã–π URL –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        min_size: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö
        
    Returns:
        bool: True –µ—Å–ª–∏ —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    content_type = headers.get('content-type', '').lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º MIME-—Ç–∏–ø
    if not validate_mime_type(content_type):
        logger.warning(
            "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π MIME-—Ç–∏–ø –¥–ª—è %s: %s",
            url,
            content_type
        )
        return False
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ HTML/JSON –æ—Ç–≤–µ—Ç—ã
    if 'text/html' in content_type or 'application/json' in content_type:
        logger.warning(
            "–ü–æ–ª—É—á–µ–Ω HTML/JSON –≤–º–µ—Å—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è %s. "
            "Content-Type: %s",
            url,
            content_type,
        )
        return False
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if not validate_file_size(len(image_data)):
        logger.warning(
            "–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç—ã –¥–ª—è %s: %d –±–∞–π—Ç",
            url,
            len(image_data)
        )
        return False
        
    if len(image_data) < min_size:
        logger.warning(
            "–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ñ–∞–π–ª –¥–ª—è %s. –†–∞–∑–º–µ—Ä: %d –±–∞–π—Ç.",
            url,
            len(image_data),
        )
        return False
        
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    try:
        full_path.parent.mkdir(parents=True, exist_ok=True)
    except OSError as e:
        logger.error(
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é %s: %s",
            full_path.parent,
            e
        )
        return False
        
    loop = asyncio.get_running_loop()
    error_handler = get_error_handler()
    
    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ executor –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        await loop.run_in_executor(
            None,
            process_and_save_image_sync,
            image_data,
            full_path,
            content_type,
        )
        logger.info(
            "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: %s (%d –±–∞–π—Ç)",
            full_path,
            len(image_data),
        )
        return True
        
    except (OSError, IOError) as e:
        # –û—à–∏–±–∫–∏ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
        error_handler.handle_file_error(e, full_path, "save_image")
        logger.error(
            "–û—à–∏–±–∫–∞ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ %s: %s",
            url,
            e
        )
        return False
        
    except MemoryError as e:
        # –û—à–∏–±–∫–∏ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        error_handler.handle_memory_error(e, full_path, len(image_data))
        logger.error(
            "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è %s (—Ä–∞–∑–º–µ—Ä: %d –±–∞–π—Ç): %s",
            url,
            len(image_data),
            e
        )
        return False
        
    except ValueError as e:
        # –û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Ä–∞–∑–º–µ—Ä, —Ñ–æ—Ä–º–∞—Ç, etc.)
        error_handler.handle_validation_error(e, url, "image_validation")
        logger.error(
            "–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è %s: %s",
            url,
            e
        )
        return False
        
    except Exception as e:
        # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
        error_handler.handle_image_error(e, full_path, "image_processing")
        logger.error(
            "–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è %s: %s (—Ç–∏–ø: %s)",
            url,
            e,
            type(e).__name__
        )
        
        # –ü–æ–ø—ã—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        try:
            unknown_path = full_path.with_suffix('.unknown')
            with open(unknown_path, 'wb') as f:
                f.write(image_data)
            logger.info(
                "–°–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: %s",
                unknown_path
            )
        except Exception as save_error:
            logger.error(
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏: %s",
                save_error
            )
        
        return False

# –°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ


async def download_file(
    session: AsyncSession,
    semaphore: asyncio.Semaphore,
    url: str,
    target_dir: Path,
    file_index: int,
    retries: int = 3,
) -> bool:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ URL –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é.
    
    –§—É–Ω–∫—Ü–∏—è –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π URL, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ 
    –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö, –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–µ–º–∞—Ñ–æ—Ä–∞ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è 
    –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π.
    
    Args:
        session: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è HTTP-—Å–µ—Å—Å–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
        semaphore: –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫
        url: URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        target_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∫–∞—á–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        file_index: –ò–Ω–¥–µ–∫—Å —Ñ–∞–π–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–º–µ–Ω–∏
        retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3)
    
    Returns:
        bool: True –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    Raises:
        –§—É–Ω–∫—Ü–∏—è –Ω–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –≤—Å–µ –æ—à–∏–±–∫–∏ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è
    
    Examples:
        >>> import asyncio
        >>> from curl_cffi import AsyncSession
        >>> from pathlib import Path
        >>> 
        >>> async def download_example():
        ...     semaphore = asyncio.Semaphore(5)
        ...     target = Path("./downloads")
        ...     async with AsyncSession() as session:
        ...         success = await download_file(
        ...             session=session,
        ...             semaphore=semaphore,
        ...             url="https://example.com/image.jpg",
        ...             target_dir=target,
        ...             file_index=1001,
        ...             retries=3
        ...         )
        ...         print(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {success}")
        >>> 
        >>> # asyncio.run(download_example())
    
    Note:
        - –§—É–Ω–∫—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç URL –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        - –ü—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ 429 (Rate Limit) –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        - –°–µ–º–∞—Ñ–æ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–µ—Ç–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π, –Ω–µ –±–ª–æ–∫–∏—Ä—É—è –ø–æ–≤—Ç–æ—Ä—ã
        - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (JPEG, PNG, WebP, GIF)
    """
    if not url:
        logger.error("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å URL
    if not validate_download_request(url):
        logger.error(f"–û–ø–∞—Å–Ω—ã–π –∏–ª–∏ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π URL: {url}")
        return False
    
    base_filename = f"{file_index}"
    full_path = await generate_unique_filename(target_dir, base_filename)
    attempt = 0
    
    while attempt < retries:
        try:
            headers = {
                'User-Agent': random.choice(USER_AGENTS),
                'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
            }
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–º–∞—Ñ–æ—Ä —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–µ—Ç–µ–≤–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏
            async with semaphore:
                response = await session.get(
                    url,
                    headers=headers,
                    timeout=DOWNLOAD_TIMEOUT,
                )
                response.raise_for_status()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –≤–Ω–µ —Å–µ–º–∞—Ñ–æ—Ä–∞
            if await handle_and_save_response(
                response.content,
                response.headers,
                full_path,
                url,
            ):
                return True
                
        except errors.RequestsError as e:
            error_handler = get_error_handler()
            if e.response and e.response.status_code == 429:
                attempt += 1
                if attempt < retries:
                    wait_time = (2 ** attempt) + random.uniform(0, 1)
                    print(f"‚è≥ –°–µ—Ä–≤–µ—Ä –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è {url}")
                    print(f"   –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ {attempt}/{retries} —á–µ—Ä–µ–∑ {wait_time:.1f} —Å–µ–∫...")
                    # –û–∂–∏–¥–∞–Ω–∏–µ –≤–Ω–µ —Å–µ–º–∞—Ñ–æ—Ä–∞
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    print(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è {url} (429 Too Many Requests)")
            else:
                error_handler.handle_download_error(e, url, attempt, retries)
        except Exception as e:
            error_handler = get_error_handler()
            error_handler.handle_download_error(e, url, attempt, retries)
        
        attempt += 1
        if attempt < retries:
            # –û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º –≤–Ω–µ —Å–µ–º–∞—Ñ–æ—Ä–∞
            await asyncio.sleep(1)
    
    return False


async def download_file_with_session(
    session: AsyncSession,
    semaphore: asyncio.Semaphore,
    url: str,
    target_dir: Path,
    file_index: int,
    retries: int,
    progress_bar,
    session_manager
) -> Tuple[bool, float]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞—É–∑—ã/–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
    
    Args:
        session: HTTP —Å–µ—Å—Å–∏—è
        semaphore: –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        url: URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        target_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        file_index: –ò–Ω–¥–µ–∫—Å —Ñ–∞–π–ª–∞
        retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
        progress_bar: –û–±—ä–µ–∫—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        session_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞—É–∑–æ–π
        
    Returns:
        Tuple[bool, float]: (—É—Å–ø–µ—Ö, —Ä–∞–∑–º–µ—Ä_–≤_–º–±)
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∂–¥–∞—Ç—å –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    if not await session_manager.wait_if_paused():
        return False, 0.0  # –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞
    
    success = await download_file(
        session, semaphore, url, target_dir, file_index, retries
    )
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å —Å–µ—Å—Å–∏–∏
    await session_manager.update_progress(url, success)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    size_mb = 0.0
    if success:
        try:
            base_filename = f"{file_index}"
            full_path = await generate_unique_filename(target_dir, base_filename)
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ä–µ–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª (–º–æ–∂–µ—Ç –∏–º–µ—Ç—å —Å—É—Ñ—Ñ–∏–∫—Å .1, .2 –∏ —Ç.–¥.)
            for potential_path in target_dir.glob(f"{file_index}*.jpeg"):
                if await aiofiles.os.path.exists(potential_path):
                    stat_info = await aiofiles.os.stat(potential_path)
                    size_mb = stat_info.st_size / (1024 * 1024)
                    break
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è {url}: {e}")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    if hasattr(progress_bar, 'update'):
        progress_bar.update(1)
    
    return success, size_mb


async def download_file_with_progress(
    session: AsyncSession,
    semaphore: asyncio.Semaphore,
    url: str,
    target_dir: Path,
    file_index: int,
    retries: int,
    progress_bar
) -> Tuple[bool, float]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞.
    
    Args:
        session: HTTP —Å–µ—Å—Å–∏—è
        semaphore: –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        url: URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        target_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        file_index: –ò–Ω–¥–µ–∫—Å —Ñ–∞–π–ª–∞
        retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
        progress_bar: –û–±—ä–µ–∫—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        
    Returns:
        Tuple[bool, float]: (—É—Å–ø–µ—Ö, —Ä–∞–∑–º–µ—Ä_–≤_–º–±)
    """
    success = await download_file(
        session, semaphore, url, target_dir, file_index, retries
    )
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    size_mb = 0.0
    if success:
        try:
            base_filename = f"{file_index}"
            full_path = await generate_unique_filename(target_dir, base_filename)
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ä–µ–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª (–º–æ–∂–µ—Ç –∏–º–µ—Ç—å —Å—É—Ñ—Ñ–∏–∫—Å .1, .2 –∏ —Ç.–¥.)
            for potential_path in target_dir.glob(f"{file_index}*.jpeg"):
                if await aiofiles.os.path.exists(potential_path):
                    stat_info = await aiofiles.os.stat(potential_path)
                    size_mb = stat_info.st_size / (1024 * 1024)
                    break
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è {url}: {e}")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    progress_bar.update(1)
    
    return success, size_mb


async def download_images(
    session: AsyncSession,
    urls: List[str],
    target_dir: Path,
    start_index: int = 1000,
    retries: int = 3,
) -> int:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ URL –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    """
    await create_dir(target_dir)

    semaphore = asyncio.Semaphore(MAX_CONCURRENT_DOWNLOADS)
    logger.info(
        "–ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ '%s'...",
        len(urls),
        target_dir,
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-—Ç—Ä–µ–∫–µ—Ä
    progress_tracker = get_progress_tracker()
    successful_downloads = 0
    failed_downloads = 0
    total_size_mb = 0.0
    
    async with progress_tracker.track_download_progress(
        len(urls), "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
    ) as progress_bar:
        tasks = []
        for i, url in enumerate(urls):
            task = asyncio.create_task(
                download_file_with_progress(
                    session,
                    semaphore,
                    url,
                    target_dir,
                    start_index + i,
                    retries,
                    progress_bar
                )
            )
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        for result in results:
            if isinstance(result, tuple) and len(result) == 2:
                success, size_mb = result
                if success:
                    successful_downloads += 1
                    total_size_mb += size_mb
                else:
                    failed_downloads += 1
            elif isinstance(result, Exception):
                failed_downloads += 1
                logger.error(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {result}")
            else:
                failed_downloads += 1

    logger.info(
        "–í—Å–µ–≥–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ: %d –∏–∑ %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.",
        successful_downloads,
        len(urls),
    )
    return successful_downloads


async def download_images_with_session(
    session: AsyncSession,
    urls: List[str],
    target_dir: Path,
    start_index: int = 1000,
    retries: int = 3,
    enable_pause_resume: bool = True
) -> int:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ URL —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞—É–∑—ã/–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
    
    Args:
        session: HTTP —Å–µ—Å—Å–∏—è
        urls: –°–ø–∏—Å–æ–∫ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        target_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        start_index: –ù–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Ñ–∞–π–ª–æ–≤
        retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
        enable_pause_resume: –í–∫–ª—é—á–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–∞—É–∑—ã/–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        
    Returns:
        int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    await create_dir(target_dir)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π
    session_manager = get_session_manager() if enable_pause_resume else None
    
    if session_manager:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
        session_id = await session_manager.create_session(
            urls=urls,
            start_index=start_index,
            retries=retries,
            target_dir=target_dir
        )
        logger.info(f"–°–æ–∑–¥–∞–Ω–∞ —Å–µ—Å—Å–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {session_id}")
        logger.info("üìå –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –ø–∞—É–∑—ã. –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –Ω–∞–∂–∞—Ç–∏–µ –¥–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
    
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_DOWNLOADS)
    logger.info(
        "–ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ '%s'...",
        len(urls),
        target_dir,
    )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-—Ç—Ä–µ–∫–µ—Ä
    progress_tracker = get_progress_tracker()
    successful_downloads = 0
    failed_downloads = 0
    total_size_mb = 0.0
    start_time = time.time()
    
    try:
        if enable_pause_resume and session_manager:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            with progress_tracker.create_pausable_progress_bar(
                len(urls), "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", 
                session_manager
            ) as progress_bar:
                tasks = []
                for i, url in enumerate(urls):
                    task = asyncio.create_task(
                        download_file_with_session(
                            session,
                            semaphore,
                            url,
                            target_dir,
                            start_index + i,
                            retries,
                            progress_bar,
                            session_manager
                        )
                    )
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
        else:
            # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –±–µ–∑ –ø–∞—É–∑—ã/–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            async with progress_tracker.track_download_progress(
                len(urls), "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
            ) as progress_bar:
                tasks = []
                for i, url in enumerate(urls):
                    task = asyncio.create_task(
                        download_file_with_progress(
                            session,
                            semaphore,
                            url,
                            target_dir,
                            start_index + i,
                            retries,
                            progress_bar
                        )
                    )
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        for result in results:
            if isinstance(result, tuple) and len(result) == 2:
                success, size_mb = result
                if success:
                    successful_downloads += 1
                    total_size_mb += size_mb
                else:
                    failed_downloads += 1
            elif isinstance(result, Exception):
                failed_downloads += 1
                logger.error(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {result}")
            else:
                failed_downloads += 1
    
    finally:
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        elapsed_time = time.time() - start_time
        await show_download_stats(
            downloaded=successful_downloads,
            skipped=0,
            errors=failed_downloads,
            total_size_mb=total_size_mb,
            elapsed_time=elapsed_time
        )
        
        # –û—á–∏—â–∞–µ–º —Å–µ—Å—Å–∏—é –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
        if session_manager:
            if session_manager.cancel_event.is_set():
                logger.info("üóø –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            else:
                await session_manager.cleanup_session()
                logger.info("‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
    
    logger.info(
        "–í—Å–µ–≥–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ: %d –∏–∑ %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.",
        successful_downloads,
        len(urls),
    )
    return successful_downloads


async def run_download_session(
    urls: List[str],
    start_index: int = 1000,
    retries: int = 3,
) -> None:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é —Å–µ—Å—Å–∏—é —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º —Ä–µ—Å—É—Ä—Å–æ–≤.
    
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ 
    —Å–æ–∑–¥–∞—ë—Ç —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ 
    –≤—ã–ø–æ–ª–Ω—è–µ—Ç –æ—á–∏—Å—Ç–∫—É —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.
    
    Args:
        urls: –°–ø–∏—Å–æ–∫ URL-–∞–¥—Ä–µ—Å–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        start_index: –ù–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –Ω—É–º–µ—Ä–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1000)
        retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3)
    
    Returns:
        None: –§—É–Ω–∫—Ü–∏—è –Ω–∏—á–µ–≥–æ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç, –≤—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤—ã–≤–æ–¥–∏—Ç—Å—è —á–µ—Ä–µ–∑ –ª–æ–≥–∏
    
    Examples:
        >>> import asyncio
        >>> 
        >>> urls = [
        ...     "https://example.com/image1.jpg",
        ...     "https://example.com/image2.png",
        ...     "https://example.com/image3.webp"
        ... ]
        >>> 
        >>> async def example_session():
        ...     await run_download_session(
        ...         urls=urls,
        ...         start_index=1000,
        ...         retries=3
        ...     )
        >>> 
        >>> # asyncio.run(example_session())
        
        –ü—Ä–∏–º–µ—Ä —Å –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏:
        >>> # python main.py download --start-index 2000 --retries 5 \
        >>> #   "https://site1.com/pic.jpg" "https://site2.com/photo.png"
    
    Note:
        - –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ {IMAGE_DIR}/{DEFAULT_DOWNLOAD_DIR_NAME}/
        - –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤: start_index.jpeg, start_index+1.jpeg, –∏ —Ç.–¥.
        - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
        - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤—ã–≤–æ–¥–∏—Ç—Å—è –≤ –ª–æ–≥–∏
    """
    if not urls:
        logger.warning("–ù–µ –ø–µ—Ä–µ–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.")
        return

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
    resource_manager = get_resource_manager()
    initial_memory = resource_manager.get_memory_usage()
    logger.info(
        f"–ù–∞—á–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {initial_memory.get('rss_mb', 0):.1f} MB"
    )

    target_dir = IMAGE_DIR / DEFAULT_DOWNLOAD_DIR_NAME
    await create_dir(target_dir)

    logger.info(
        "%d URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ '%s'",
        len(urls),
        target_dir,
    )

    try:
        async with AsyncSession() as session:
            successful_count = await download_images(
                session=session,
                urls=urls,
                target_dir=target_dir,
                start_index=start_index,
                retries=retries,
            )
    finally:
        # –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        final_memory = resource_manager.get_memory_usage()
        memory_used = final_memory.get('rss_mb', 0) - initial_memory.get('rss_mb', 0)
        
        if memory_used > 50:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏ –∑–∞ —Å–µ—Å—Å–∏—é: {memory_used:.1f} MB")
            
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        cleanup_stats = await resource_manager.cleanup_all()
        logger.debug(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {cleanup_stats}")

    if successful_count == len(urls):
        logger.info("–í—Å–µ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω—ã!")
    else:
        logger.warning(
            "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ %d –∏–∑ %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
            successful_count,
            len(urls),
        )


async def run_download_session_with_pause(
    urls: List[str],
    start_index: int = 1000,
    retries: int = 3,
    enable_pause_resume: bool = True,
) -> None:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–µ—Å—Å–∏—é —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞—É–∑—ã/–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
    
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é 
    –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞.
    
    Args:
        urls: –°–ø–∏—Å–æ–∫ URL-–∞–¥—Ä–µ—Å–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        start_index: –ù–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –Ω—É–º–µ—Ä–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤
        retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
        enable_pause_resume: –í–∫–ª—é—á–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–∞—É–∑—ã/–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    
    Returns:
        None: –§—É–Ω–∫—Ü–∏—è –Ω–∏—á–µ–≥–æ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç
    
    Features:
        - –ü–∞—É–∑–∞ –ø–æ Ctrl+C, –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –Ω–∞–∂–∞—Ç–∏–µ –¥–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏ –≤ JSON
        - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞
        - –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    if not urls:
        logger.warning("–ù–µ –ø–µ—Ä–µ–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
    resource_manager = get_resource_manager()
    initial_memory = resource_manager.get_memory_usage()
    logger.info(
        f"–ù–∞—á–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {initial_memory.get('rss_mb', 0):.1f} MB"
    )
    
    target_dir = IMAGE_DIR / DEFAULT_DOWNLOAD_DIR_NAME
    await create_dir(target_dir)
    
    logger.info(
        "%d URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ '%s'",
        len(urls),
        target_dir,
    )
    
    if enable_pause_resume:
        logger.info("üîÑ –†–µ–∂–∏–º –ø–∞—É–∑—ã/–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–∫–ª—é—á–µ–Ω")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è
        session_manager = get_session_manager()
        existing_session = await session_manager.load_session()
        
        if existing_session:
            remaining_urls = session_manager.get_remaining_urls()
            if remaining_urls:
                stats = session_manager.get_session_stats()
                logger.info(
                    f"üîÑ –ù–∞–π–¥–µ–Ω–∞ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è! "
                    f"–û—Å—Ç–∞–ª–æ—Å—å: {len(remaining_urls)} –∏–∑ {stats['total_urls']}"
                )
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Å—Ç–∞–≤—à–∏–º–∏—Å—è URL
                urls = remaining_urls
    
    try:
        async with AsyncSession() as session:
            successful_count = await download_images_with_session(
                session=session,
                urls=urls,
                target_dir=target_dir,
                start_index=start_index,
                retries=retries,
                enable_pause_resume=enable_pause_resume
            )
    finally:
        # –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        final_memory = resource_manager.get_memory_usage()
        memory_used = final_memory.get('rss_mb', 0) - initial_memory.get('rss_mb', 0)
        
        if memory_used > 50:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏ –∑–∞ —Å–µ—Å—Å–∏—é: {memory_used:.1f} MB")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        cleanup_stats = await resource_manager.cleanup_all()
        logger.debug(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {cleanup_stats}")
    
    if successful_count == len(urls):
        logger.info("–í—Å–µ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω—ã!")
    else:
        logger.warning(
            "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ %d –∏–∑ %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
            successful_count,
            len(urls),
        )
